# app.py
# ------------------------------------------------------------
# æ—¥æœ¬èªã®æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«ï¼‹èª¬æ˜æ–‡ã‹ã‚‰ã‚¸ãƒ£ãƒ³ãƒ«ã‚’åˆ†é¡ã™ã‚‹ç°¡æ˜“ã‚¢ãƒ—ãƒª
# - å­¦ç¿’ãƒãƒ¼ãƒˆã§ä¿å­˜ã—ãŸãƒ¢ãƒ‡ãƒ«ã«ä¸¡å¯¾å¿œ:
#   * genre_pipeline.joblib + labels.npyï¼ˆæ¨å¥¨ï¼‰
#   * genre_pipeline.joblib + label_encoder.joblibï¼ˆæ—§ï¼‰
# - é¡ä¼¼æœ¬æ¤œç´¢ã¯ tfidf_corpus.npz / corpus_meta.joblib ãŒã‚ã‚Œã°è‡ªå‹•ã§ON
# ------------------------------------------------------------

from pathlib import Path
import numpy as np
import streamlit as st
from joblib import load
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics.pairwise import cosine_similarity

# ------------------------------------------------------------
# ãƒ‘ã‚¹è¨­å®š
# ------------------------------------------------------------
BASE_DIR = Path(__file__).resolve().parent
MODELS_DIR = BASE_DIR / "models"

PIPE_PATH = MODELS_DIR / "genre_pipeline.joblib"
LE_JOBLIB_PATH = MODELS_DIR / "label_encoder.joblib"   # æ—§ä¿å­˜å½¢å¼
LABELS_NPY_PATH = MODELS_DIR / "labels.npy"            # ç¾åœ¨ã®ä¿å­˜å½¢å¼

CORPUS_NPZ_PATH = MODELS_DIR / "tfidf_corpus.npz"      # é¡ä¼¼æœ¬ï¼ˆä»»æ„ï¼‰
CORPUS_META_PATH = MODELS_DIR / "corpus_meta.joblib"   # é¡ä¼¼æœ¬ï¼ˆä»»æ„ï¼‰

# ------------------------------------------------------------
# ä¾¿åˆ©é–¢æ•°
# ------------------------------------------------------------
def load_label_encoder() -> LabelEncoder:
    """labels.npy ã‹ label_encoder.joblib ã®ã©ã¡ã‚‰ã‹ã‚’èª­ã¿ã€LabelEncoder ã‚’è¿”ã™ã€‚"""
    if LE_JOBLIB_PATH.exists():
        le = load(LE_JOBLIB_PATH)
        if not isinstance(le, LabelEncoder):
            raise TypeError("label_encoder.joblib ã¯ LabelEncoder ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return le

    if LABELS_NPY_PATH.exists():
        classes = np.load(LABELS_NPY_PATH, allow_pickle=True)
        le = LabelEncoder().fit(classes)
        return le

    raise FileNotFoundError("ãƒ©ãƒ™ãƒ«æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆlabels.npy ã¾ãŸã¯ label_encoder.joblib ãŒå¿…è¦ï¼‰")


def get_step(pipeline, *names):
    """
    Pipeline.named_steps ã‹ã‚‰ã€å€™è£œåã®ã„ãšã‚Œã‹ã‚’è¿”ã™ã€‚
    å­¦ç¿’æ™‚ã®æ›¸ãæ–¹ã®é•ã„ï¼ˆ('tfidf', ...) vs make_pipeline(TfidfVectorizer)ï¼‰ã«å¯¾å¿œã€‚
    """
    for n in names:
        if n in pipeline.named_steps:
            return pipeline.named_steps[n]
    return None


def softmax_like(margin: np.ndarray) -> np.ndarray:
    """SVM ã® decision_function ã‚’ç¢ºç‡é¢¨ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆä¾¿å®œçš„ï¼‰ã€‚"""
    x = margin - np.max(margin)
    ex = np.exp(x)
    p = ex / np.sum(ex)
    return p


def concat_text(title: str, description: str) -> str:
    title = (title or "").strip()
    desc = (description or "").strip()
    return (title + " " + desc).strip()


# ------------------------------------------------------------
# ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
# ------------------------------------------------------------
st.set_page_config(page_title="Book Genre Classifier", layout="wide")

st.sidebar.title("ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹")
try:
    pipe = load(PIPE_PATH)
    st.sidebar.success(f"âœ… Pipeline: {PIPE_PATH.name}")
except Exception as e:
    st.sidebar.error("âŒ Pipeline ãŒèª­ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚å­¦ç¿’ãƒãƒ¼ãƒˆã§ä¿å­˜ã—ã¦ãã ã•ã„ã€‚")
    st.exception(e)
    st.stop()

try:
    le: LabelEncoder = load_label_encoder()
    st.sidebar.success("âœ… Labels: labels.npy / label_encoder.joblib")
except Exception as e:
    st.sidebar.error("âŒ ãƒ©ãƒ™ãƒ«æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    st.exception(e)
    st.stop()

# é¡ä¼¼æœ¬ï¼ˆä»»æ„ï¼‰
similarity_ready = False
tfidf_corpus = None
corpus_meta = None
try:
    if CORPUS_NPZ_PATH.exists() and CORPUS_META_PATH.exists():
        tfidf_corpus = np.load(CORPUS_NPZ_PATH)
        corpus_meta = load(CORPUS_META_PATH)  # {"titles": [...], "genres": [...], ...} ã‚’æƒ³å®š
        similarity_ready = "X" in tfidf_corpus and "titles" in corpus_meta
        if similarity_ready:
            st.sidebar.info("ğŸ” é¡ä¼¼æœ¬ã‚³ãƒ¼ãƒ‘ã‚¹: æœ‰åŠ¹")
        else:
            st.sidebar.warning("ğŸ” é¡ä¼¼æœ¬ã‚³ãƒ¼ãƒ‘ã‚¹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒä¸å®Œå…¨ã§ã™ã€‚")
    else:
        st.sidebar.write("ğŸ” é¡ä¼¼æœ¬ã‚³ãƒ¼ãƒ‘ã‚¹: ãªã—ï¼ˆä»»æ„æ©Ÿèƒ½ï¼‰")
except Exception as e:
    st.sidebar.warning("ğŸ” é¡ä¼¼æœ¬ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸï¼ˆä»»æ„ï¼‰ã€‚")
    st.sidebar.code(str(e))

# ------------------------------------------------------------
# UI
# ------------------------------------------------------------
st.title("ğŸ“š æ—¥æœ¬èªãƒ»æ›¸ç±ã‚¸ãƒ£ãƒ³ãƒ«åˆ†é¡ï¼ˆSVMï¼‰")

with st.expander("â„¹ï¸ ä½¿ã„æ–¹", expanded=False):
    st.write(
        "- ä¸Šã«å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ï¼ˆ`models/genre_pipeline.joblib`ï¼‰ãŒå¿…è¦ã§ã™ã€‚\n"
        "- ãƒ©ãƒ™ãƒ«ã¯ `models/labels.npy`ï¼ˆæ¨å¥¨ï¼‰ã‹ `models/label_encoder.joblib` ã®ã©ã¡ã‚‰ã‹ãŒå¿…è¦ã§ã™ã€‚\n"
        "- é¡ä¼¼æœ¬ã¯ä»»æ„ã§ `tfidf_corpus.npz` ã¨ `corpus_meta.joblib` ãŒã‚ã‚Œã°è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚"
    )

col1, col2 = st.columns(2)
title = col1.text_input("ã‚¿ã‚¤ãƒˆãƒ«", value="", placeholder="ä¾‹ï¼‰æ©Ÿæ¢°å­¦ç¿’å…¥é–€")
description = col2.text_area("èª¬æ˜ï¼ˆè‘—è€…/å‡ºç‰ˆç¤¾/æ¦‚è¦ãªã©ï¼‰", height=130, placeholder="ä¾‹ï¼‰è‘—è€…â—¯â—¯ï¼å‡ºç‰ˆç¤¾â–³â–³ï¼â€¦")

run = st.button("ğŸ”® äºˆæ¸¬ã™ã‚‹", type="primary")

# ------------------------------------------------------------
# äºˆæ¸¬
# ------------------------------------------------------------
if run:
    user_text = concat_text(title, description)
    if not user_text:
        st.warning("ã‚¿ã‚¤ãƒˆãƒ«ã‹èª¬æ˜ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # ãã®ã¾ã¾ pipeline ã§æ¨è«–
    try:
        y_pred = pipe.predict([user_text])[0]
    except Exception as e:
        st.error("æ¨è«–ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        st.exception(e)
        st.stop()

    # decision_function ãŒã‚ã‚Œã°ã€ç¢ºä¿¡åº¦ã‚‚å‡ºã™
    try:
        margins = pipe.decision_function([user_text])  # shape: (1, n_classes) or list-like (ovo)
        if isinstance(margins, list):  # 2å€¤ã‚„ OVO ã®å ´åˆã®ç°¡æ˜“å¯¾å‡¦
            margins = margins[0]
        probs = softmax_like(np.array(margins).ravel())
        top_idx = np.argsort(probs)[::-1]
        class_names = le.classes_
        st.subheader("ğŸ¯ äºˆæ¸¬çµæœ")
        st.markdown(f"**äºˆæ¸¬ã‚¸ãƒ£ãƒ³ãƒ«:** `{y_pred}`")

        # ä¸Šä½5ä»¶ã®ç¢ºä¿¡åº¦ã‚’è¡¨ç¤º
        k = min(5, len(class_names))
        top_table = [
            {"rank": i + 1, "genre": class_names[idx], "score": float(probs[idx])}
            for i, idx in enumerate(top_idx[:k])
        ]
        st.table(top_table)

    except Exception:
        # decision_function ãŒç„¡ã„ãƒ¢ãƒ‡ãƒ«ã§ã‚‚æœ€ä½é™è¡¨ç¤º
        st.subheader("ğŸ¯ äºˆæ¸¬çµæœ")
        st.markdown(f"**äºˆæ¸¬ã‚¸ãƒ£ãƒ³ãƒ«:** `{y_pred}`")
        st.caption("ï¼ˆã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ç¢ºä¿¡åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“ï¼‰")

    # --------------------------------------------------------
    # é¡ä¼¼æœ¬ï¼ˆä»»æ„ï¼‰
    # --------------------------------------------------------
    if similarity_ready:
        st.markdown("---")
        st.subheader("ğŸ” é¡ä¼¼ã—ã¦ã„ã‚‹æœ¬ï¼ˆã‚³ãƒ¼ãƒ‘ã‚¹å†…ï¼‰")

        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–å™¨ã‚’å–å¾—ï¼ˆä¸¡å¯¾å¿œï¼‰
        vect = get_step(pipe, "tfidf", "tfidfvectorizer")
        if vect is None:
            st.info("ãƒ™ã‚¯ãƒˆãƒ«åŒ–å™¨ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€é¡ä¼¼æœ¬æ¤œç´¢ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
        else:
            try:
                # å…¥åŠ›ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
                q_vec = vect.transform([user_text])

                # ã‚³ãƒ¼ãƒ‘ã‚¹è¡Œåˆ—
                X_corpus = tfidf_corpus["X"]  # csr_matrix ã‚’æƒ³å®š
                sims = cosine_similarity(q_vec, X_corpus).ravel()

                # åŒã‚¸ãƒ£ãƒ³ãƒ«å„ªå…ˆã§ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆåŒç‚¹ãªã‚‰å…¨ä½“ã‹ã‚‰ï¼‰
                titles = corpus_meta.get("titles", [])
                genres = corpus_meta.get("genres", [])
                same_genre_idx = [i for i, g in enumerate(genres) if g == y_pred] if genres else []

                def topk_from(indices, k=10):
                    if not indices:
                        return []
                    idx = np.argsort(sims[indices])[::-1][:k]
                    return [indices[i] for i in idx]

                picks = topk_from(same_genre_idx, k=10)
                if len(picks) < 5:
                    # è¶³ã‚Šãªã‘ã‚Œã°å…¨ä½“ã‹ã‚‰ã‚‚è£œå®Œ
                    extra = np.argsort(sims)[::-1][:10]
                    extra = [i for i in extra if i not in picks]
                    picks = (picks + extra)[:10]

                rows = []
                for i in picks:
                    rows.append({
                        "title": titles[i] if i < len(titles) else f"id:{i}",
                        "genre": genres[i] if i < len(genres) else "-",
                        "similarity": float(sims[i]),
                    })

                if rows:
                    st.dataframe(rows, use_container_width=True)
                else:
                    st.write("é¡ä¼¼æœ¬ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

            except Exception as e:
                st.info("é¡ä¼¼æœ¬æ¤œç´¢ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼ˆä»»æ„æ©Ÿèƒ½ï¼‰ã€‚")
                st.exception(e)

# ------------------------------------------------------------
# ãƒ•ãƒƒã‚¿ãƒ¼
# ------------------------------------------------------------
st.markdown("---")
st.caption("Model: LinearSVC + TF-IDFï¼ˆå­¦ç¿’ãƒãƒ¼ãƒˆã‹ã‚‰ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼‰ / UI: Streamlit")
